{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szH27J0HKlBg"
      },
      "source": [
        "# **Sall-e Project**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LjCxebjxKRTe",
        "outputId": "1412645b-4328-45e9-de16-3b3060682521"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python\n",
        "!pip install pillow-avif-plugin\n",
        "!pip install ultralytics"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ytx3bYt_kjr"
      },
      "source": [
        "# Detect Inference 2\n",
        "[HF Source](https://huggingface.co/turhancan97/yolov5-obb-trash-detection)\\\n",
        "Acc: High"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyYaVBQ6_qcO",
        "outputId": "6d6ad682-3ed0-4c96-8a8b-a206adea17da"
      },
      "outputs": [],
      "source": [
        "import yolov5\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# Define paths\n",
        "TESTING_FOLDER = \"/content/drive/My Drive/Sall-e/testing\"\n",
        "DETECT_FOLDER = \"/content/drive/My Drive/Sall-e/detect2\"\n",
        "MODEL_NAME = 'turhancan97/yolov5-detect-trash-classification'\n",
        "\n",
        "# Ensure the detect folder exists\n",
        "os.makedirs(DETECT_FOLDER, exist_ok=True)\n",
        "\n",
        "# Load the pre-trained YOLOv5 model\n",
        "model = yolov5.load(MODEL_NAME)\n",
        "\n",
        "# Set model parameters\n",
        "model.conf = 0.25  # NMS confidence threshold\n",
        "model.iou = 0.15   # NMS IoU threshold\n",
        "model.max_det = 1000  # Maximum number of detections per image\n",
        "\n",
        "# Process each testing image\n",
        "for i in range(1, 7):\n",
        "    image_path = os.path.join(TESTING_FOLDER, f\"testing_{i}.jpg\")\n",
        "    detect_path = os.path.join(DETECT_FOLDER, f\"detect_{i}.jpg\")\n",
        "\n",
        "    # Read the image\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        print(f\"Error loading {image_path}\")\n",
        "        continue\n",
        "\n",
        "    # Perform object detection\n",
        "    results = model(img, size=416)\n",
        "\n",
        "    # Draw bounding boxes on the image\n",
        "    for result in results.pred[0]:\n",
        "        x1, y1, x2, y2, conf, cls = result.tolist()\n",
        "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
        "\n",
        "        # Draw the rectangle and confidence label\n",
        "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "        label = f\"Garbage {conf:.2f}\"\n",
        "        cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    # Save the processed image directly into the detect3 folder\n",
        "    cv2.imwrite(detect_path, img)\n",
        "    print(f\"Detection completed for {image_path}, saved as {detect_path}\")\n",
        "\n",
        "print(\"All detections completed and saved in the detect2 folder.\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDPMxVafDdO9"
      },
      "source": [
        "# Detect Inference 3\n",
        "[HF Source](https://huggingface.co/Yorai/detr-resnet-50_finetuned_detect-waste)\\\n",
        "Acc: Medium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDJl3tcEDehL",
        "outputId": "2ced62c1-0c0b-4565-84d7-d3124fedfc08"
      },
      "outputs": [],
      "source": [
        "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
        "import torch\n",
        "import cv2\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Define paths\n",
        "TESTING_FOLDER = \"/content/drive/My Drive/Sall-e/testing\"\n",
        "DETECT_FOLDER = \"/content/drive/My Drive/Sall-e/detect3\"\n",
        "MODEL_PATH = \"Yorai/detr-resnet-50_finetuned_detect-waste\"\n",
        "\n",
        "# Ensure the detect folder exists\n",
        "os.makedirs(DETECT_FOLDER, exist_ok=True)\n",
        "\n",
        "# Load the DETR model and processor\n",
        "processor = DetrImageProcessor.from_pretrained(MODEL_PATH)\n",
        "model = DetrForObjectDetection.from_pretrained(MODEL_PATH)\n",
        "\n",
        "# Process each testing image\n",
        "for i in range(1, 7):\n",
        "    image_path = os.path.join(TESTING_FOLDER, f\"testing_{i}.jpg\")\n",
        "    detect_path = os.path.join(DETECT_FOLDER, f\"detect_{i}.jpg\")\n",
        "\n",
        "    # Read the image\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    img_cv = cv2.imread(image_path)\n",
        "    if img_cv is None:\n",
        "        print(f\"Error loading {image_path}\")\n",
        "        continue\n",
        "\n",
        "    # Preprocess image for DETR\n",
        "    inputs = processor(images=image, return_tensors=\"pt\")\n",
        "\n",
        "    # Perform object detection\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Process detections\n",
        "    target_sizes = torch.tensor([image.size[::-1]])  # PIL image size is (width, height)\n",
        "    results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.5)[0]\n",
        "\n",
        "    # Draw bounding boxes on the image\n",
        "    for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
        "        x1, y1, x2, y2 = map(int, box.tolist())  # Get bbox coordinates\n",
        "        confidence = score.item()  # Get confidence score\n",
        "\n",
        "        # Draw the rectangle and confidence label\n",
        "        cv2.rectangle(img_cv, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "        label_text = f\"Garbage {confidence:.2f}\"\n",
        "        cv2.putText(img_cv, label_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    # Save the processed image\n",
        "    cv2.imwrite(detect_path, img_cv)\n",
        "    print(f\"Detection completed for {image_path}, saved as {detect_path}\")\n",
        "\n",
        "print(\"All detections completed and saved in the detect3 folder.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "tDpCbkaosddZ",
        "BWaBtMartXVm",
        "PICeha7-6C1Q",
        "l9FzCcOw-id_",
        "3Ytx3bYt_kjr",
        "elKObUEQcJ7I"
      ],
      "history_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.7 (main, Oct 10 2024, 10:50:01) [Clang 14.0.0 (clang-1400.0.29.202)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "f1062708a37074d70712b695aadee582e0b0b9f95f45576b5521424137d05fec"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
